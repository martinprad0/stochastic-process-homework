%%--WARNINGS-----------------------------------------------------
% chktex-file 9  - Half closed intervals
% chktex-file 17 - Half closed intervals
% chktex-file 36 - Space in front of parenthesis?

\section{Exercise 1}
Consider a sequence of i.i.d.~random variables ${(X_i)}_{i\in\N}$ with $\E X_i = 0$ and $\Var X_i = 1$ for every $i\in \N$.

\begin{enumerate}
    \item Show with th Law of Large Numbers that,
    \[ \lim_{n\to\infty} \|X_1,\ldots,X_n\|_2 - \sqrt{n} \to 0 \]
    \begin{enumerate}[label=(\alph*)]
        \item in $\mathbb{P}$,
        \item a.e.,
        \item in distribution,
        \item Show that if $X_i \in L^p$ for some $p>1$, then it converges in $L^q$ for every $q \in [1\leq p)$.
    \end{enumerate} 
    \item Infer from the previous results that for
    \[ \text{Law}(X_1 , \ldots, X_n) \approx \text{UNI}(\sqrt{n} \S^{n-1}) \]
\end{enumerate}

\subsection*{Solution Part 1}

\begin{theorem}[Laws of Large Numbers]\label{loln}
Let ${(X_i)}_{i\in\N}$ be a sequence of i.i.d.~random variables such that $\E X_i = \mu$ for every $i\in\N$, and let $\overline{X_n} = \frac{1}{n} \sum_{i = 1}^n X_i$. Then,
\begin{equation}\label{wloln}\tag{Weak Law of Large Numbers}
    \lim_{n\to\infty} \P\{\|\overline{X_n} - \mu\| > \varepsilon\} = 0,\;\forall \varepsilon > 0.
\end{equation}
\begin{equation}\label{sloln}\tag{Strong Law of Large Numbers}
    \P\{\lim_{n\to\infty} \overline{X_n} \neq \mu\} = 0.
\end{equation}
\hfill $\square$
\end{theorem}

\begin{definition}[Convergence in probability]
Let ${(X_n)}_{n\in \N}$ be a sequence of random variables. We say that $X_n$ converges to X in probability i.e. $X_n \overset{p}{\to} X$ when
\[ \lim_{n\to\infty} \P\{ \| X_n-X \| > \varepsilon \} = 0,\hspace*{1em} \forall \varepsilon > 0. \]
\end{definition}

\begin{definition}[Convergence almost everywhere]
    Let ${(X_n)}_{n\in \N}$ be a sequence of random variables. We say that $X_n$ converges to X almost everywhere (or almost surely) i.e. $X_n \overset{a.e.}{\to} X$ when
    \[  \P\{ \lim_{n\to\infty} X_n  \neq X \} = 0\]
\end{definition}

According to {theorem}~\ref{loln} and the previous definitions, since ${(X_i^2)}_{n\in\N}$ is still a sequence of i.i.d.~random variables,
\[ \everymath{\displaystyle}
\begin{array}{cc}
    \text{(a)} & \frac{1}{n}\|X_1, \ldots, X_n\|_2^2 = \frac{1}{n} \sum_{i = 1}^n X_i^2 \overset{p}{\longrightarrow} \E X^2 = \Var X - \E X = 1\\
    \text{(b)} & \frac{1}{n}\|X_1, \ldots, X_n\|_2^2 = \frac{1}{n} \sum_{i = 1}^n X_i^2 \overset{a.e.}{\longrightarrow} \E X^2 = \Var X - \E X = 1
\end{array} \]
Therefore,
\[ \|X_1, \ldots, X_n\|_2-\sqrt{n} \overset{p}{\longrightarrow} 0,\hspace*{2em}\|X_1, \ldots, X_n\|_2-\sqrt{n} \overset{a.e.}{\longrightarrow} 0. \]

\begin{definition}[Convergence of distribution]
    Let ${(X_n)}_{n\in \N}$ be a sequence of random variables with probability distributions $P_n$. Let $X$ a random variable with a probability distribution $P$. We say that $X_n$ converges to X in distribution i.e. $X_n \overset{d}{\to} X$ if
    \[ \lim_{n\to\infty} \E [f(X_n)] = \E[f(X)]\]
    for every bounded and continuous function $f : \mathcal{X}\to \R$.
\end{definition}

\begin{theorem}
    A direct consequence of Fatou's Lemma and Dominated Convergence is that,
    \[ X_n \overset{a.e.}{\longrightarrow} X \;\implies\; X_n \overset{p}{\longrightarrow} X \;\implies\; X_n \overset{d}{\longrightarrow}  X.\]
    \hfill $\square$
\end{theorem}

Thus, this proves that
\[ \everymath{\displaystyle}
\begin{array}{cc}
    \text{(c)} & \|X_1, \ldots, X_n\|_2-\sqrt{n} \overset{d}{\longrightarrow} 0.
\end{array} \]

\begin{definition}[Convergence in $L_p$]
    Let ${(X_n)}_{n\in \N}$ be a sequence of random variables. For some $p \in [1,\infty)$, we say that $X_n$ converges to X in $L_p$ norm i.e. $X_n \overset{L_p}{\to} X$ if $\E |X_n|^p$ and $\E |X|^p$ exist, and
    \[ \lim_{n\to\infty} \E |X_n - X|^p = 0.\]
    for every bounded and continuous function $f : \mathcal{X}\to \R$.
\end{definition}

\begin{theorem}[Exercise 1.d.]
Convergence in $L_p$ implies convergence in $L_q$ for every $q\in [1,p)$.
\end{theorem}
\begin{proof}
HÃ¶lder inequality states that for $a,b \in [1,\infty]$ such that $a^{-1} + b^{-1} = 1$ and random variables $A, B$,
\[ \|AB\|_1 = \E |AB| \leq {(\E |A|^a)}^{a^{-1}} {(\E |B|^b)}^{b^{-1}} = \|A\|_a \|B\|_b.\] 
By letting
\[ A = |X_n - X|^q,\hspace*{1em} B = 1, \]
\[ a = \frac{p}{q},\hspace*{2em} b = \frac{p}{p-q}, \]
we obtain,
\[ \everymath{\displaystyle}
\arraycolsep=1.8pt\def\arraystretch{1.8}
\begin{array}{rl}
    \E |X_n - X|^q & = \E||X_n - X|^q|\\
     & \leq {(\E |X_n - X|^{q\cdot p/q})}^{q/p} \cdot {(\E |1|^{p/(p-q)})}^{(p-q)/p}\\
     & = {(\E |X_n - X|^{p})}^{q/p}.
\end{array} \] 
The hypothesis of $q \in [1,p)$ is used on the fact that, if $q \geq p$, then $p-q \leq 0$, and if $ q < 1 $, then the $L_q$ norm wouldn't be defined.
Finally, since
\[ \lim_{n\to\infty} \E |X_n - X|^p = 0,\]
it follows that
\[ \lim_{n\to\infty} \E |X_n - X|^q \leq \lim_{n\to\infty} {(\E |X_n - X|^p)}^{q/p} = 0. \]
\end{proof}

\subsection*{Solution Part 2}

In the first place note that the function $\|\cdot\|_2$ is invariant under rotations because for any orthogonal (rotation) matrix $O \in \{M : M^T M = I\}$,
\[ \everymath{\displaystyle}
\arraycolsep=1.8pt\def\arraystretch{1.8}
\begin{array}{rl}
    \|OX\|_2 & = \angles{OX, OX}^{1/2}\\
    & = \angles{X, O^T OX}^{1/2}\\
    & = \angles{X,X}^{1/2}\\
    & = \|X\|_2
\end{array} . \]

Therefore, for any vector $Z_n \sim \mathcal{N}(0,I_n)$ the density formula, which only depends on $\|Z_n\|_2$, is invariant under rotations. Thus, for any $n\times n$ rotation matrix $O$ and measurable set $A \subset \R^2$,
\[ P(Z_n \in A) = P(OZ_n \in A) . \]
Then, by normalizing everything, we would obtain that for every measurable subset of the $(n-1)$-sphere $A\subset \S^{n-1}$,
\[ P(Z_n/\|Z_n\|_2 \in A) = P(OZ_n/\|Z_n\|_2 \in A) = P(OZ_n/\|OZ_n\|_2 \in A). \]
So it follows that $Z_n/\|Z_n\|_2$ is uniformly distributed over the $(n-1)$-sphere.

On the other hand, according to the Central Limit Theorem,
\[ \overline{Z_n} = \frac{1}{\sqrt{n}}\sum_{i = 1}^n (X_i - \E X_i)/(\sqrt{\Var X_i}) \overset{d}{\longrightarrow} Z_n.\]
According to the exercise's statement, $\E X_i = 0$ and $\Var X_i = 1$. Thus,
\[ \overline{Z_n} = \frac{\sqrt{n}}{n}\sum_{i = 1}^n X_i = \sqrt{n} \cdot \overline{X_n}. \]
Also, using the a.e.~convergence from the part 1, we can make the following approximation,
\[ \|Z_n\|_2 \approx \sqrt{n}. \]
Finally, it follows that
\[ \overline{X_n} = \frac{\overline{Z_n}}{\sqrt{n}} \approx \frac{\overline{Z_n}}{\|Z_n\|_2} \overset{d}{\longrightarrow} \frac{Z_n}{\|Z_n\|_2},  \]
which will let us conclude that the distribution of $\overline{X_n}$ which is Law$(X_1,\ldots,X_n)$ might be similar to a uniform distribution on a $(n-1)$-sphere.

